<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Tomographic Binning</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<h1>Improved Tomographic Binning of 3x2pt Lens Samples: Neural Network Classifiers and Optimal Bin
Assignments</h1>
						<p>Irene Moskowitz, Eric Gawiser, Abby Bault, Adam Broussard, Jeffery A. Newman, Joe Zuntz and the Dark Energy Science Collaboration</p>
					</header>
				<!-- Nav -->
					<nav id="nav">
						<ul>
							<li><a href="index.html#intro">Home</a></li>
							<li><a href="index.html#first" class="active">My Research</a></li>
							<li><a href="index.html#second">My Hobbies</a></li>
							<li><a href="index.html#cta">Cats!</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Content -->
							<section id="content" class="main">
								<h2>Motivation</h2>
								<p>Weak lensing and large scale structure are powerful probes of cosmology. Galaxies form in dark matter halos, so galaxy locations can be used as a tracer of the underlying large scale structure of the universe. Similarly, light traveling from distant galaxies is lensed by intervening structure, causing a statistical correlation in the measured shapes of galaxies along the same line of sight. The Vera C. Rubin Observatory's Legacy Survey of Space and Time (LSST) will observe tens of billions of galaxies over the next 10 years, from which galaxy locations and shapes can be measured. One way that information can be extracted from these measured locations and shapes is through the 3x2pt method. This is a combination of 3 different two-point correlation functions: galaxy clustering, which is the auto-correlation between galaxy shapes; cosmic shear, which is the auto-correlation between galaxy shapes; and galaxy-galaxy lensing, which is the cross-correlation between the two.</p>
								<p>If accurate spectroscopic redshifts could be attained for all the galaxies in a sample, you can compute 3D correlation functions. However, it will not be feasible to obtain spectroscopic redshifts for the tens of billions of galaxies that LSST will observe, and we must instead rely on photometric redshifts (photo-z's). Since photo-z's are less accurate, the galaxies are instead sorted into tomographic redshift bins, and angular correlation functions are computed for samples within and between bins. The necessity of binning raises the question of how to design the bins to extract the maximum amount of cosmological information.</p>
								<p>In addition to the question of binning, LSST will observe enough galaxies that the bins will not be shot noise limited. This allows us to attempt to remove galaxies with the poorest photo-z's from the sample to improve the cosmology constraints. The other question we attempt to answer with this paper is how to make this selection of galaxies with the best photo-z's using neural network classifiers.</p>
								<h2>Methodology</h2>
								<h3>Tomographic Binning</h3>
								<p>We start with three simple tomographic bin definitions: equally spaced in redshift; equally spaced in co-moving distance; and equal numbers of galaxies in each bin. To systematically probe the space of other possible bin definitions, we introduce the binning equation. The binning equation defines an integral, <i> M </i>, which integrates over the redshift distribution of your sample and the co-moving distance distribution of your sample, rasied to powers of alpha and beta respectively. We can then compute this <i> M</i> value for different values of alpha and beta, which we then divide into 12 even intervals for 12 tomographic bins. By interpolating between this <i>M</i> value and redshift, we can convert the <i>M</i> values into redshift values for the bin edges. To determine which set of bin edges is the "best", we use Fisher Forecasting to compute a Figure of Merit (FOM) for each choice of bin edges, and maximize the FOM.  </p>
								<p><span class="image left"><img src="images/paper1_alpha_beta.png" alt="" /></span>On the left is a heatmap showing the FOM values computed for a large array of alpha and beta values. The light blue square marks the alpha and beta values that correspond to bins equally spaced in redshift, the dark blue diamond marks values corresponding to bins equally spaced in co-moving distance, and the green star marks values corresponding to bins with an equal number of galaxies in each. The pink circle marks the alpha and beta that maximize the FOM, at alpha=0.25 and beta=2.0.</p>
								<h3>Sample Selection with Neural Network Classifiers</h3>
								<p>We train two Neural Network Classifiers (NNCs) to select galaxies with good photo-z's. The first type we call an Outlier NNC, and is based on <a href="https://iopscience.iop.org/article/10.3847/1538-4357/ac2147" target="_blank">Broussard & Gawiser 2021</a>. The NNC requires a training sample consisting of galaxies with photometry, a spectroscopic redshift, and a photo-z estimate. When applied to a sample of galaxies with only photometry and photo-z's, it will then estimate a confidence value for each galaxy where a confidence close to 1 corresponds to extreme confidence that the photo-z estimate for that galaxy is accurate, and a confidence close to 0 corresponds to high confidence that the photo-z estimate for that galaxy is an outlier. We can then select galaxies with high confidence values to use for cosmology, while rejecting galaxies with low confidence.</p>
								<p>The other NNC takes advantage of the fact that once a galaxy is sorted into a tomographic bin, its exact redshift estimate is no longer needed. This means that we only really care about whether the photo-z estimate is good enough to place it into the correct bin. If a bin is wide enough, something that would be considered an outlier by the Outlier NNC could still be sorted into the correct bin, and therefore should remain in the sample. We call the NNC that estimates a confidence value that a galaxy is sorted into the correct bin the Misclassification NNC.</p>
								<p><span class="image right"><img src="images/paper1_outlier_nnc.pdf" alt="" /></span>On the right is an example showing the Outlier NNC sample selection. The x-axis is the true redshift for galaxies in our sample, and the y-axis is the photo-z estimate, with non-outlier estimates falling near the diagonal. In black are all the galaxies in our sample, while the blue regions show the 75% of the sample with the highest confidence values.</p>
								<h2>Results</h2>
								<p>We used the cosmoDC2 sample of LSST-like simulated galaxies to test the tomographic binning and NNC sample selection methodologies.</p>
								<footer class="major">
									<ul class="actions special">
										<li><a href="https://arxiv.org/abs/2212.06754" class="button primary">Link to Arxiv version of the paper</a></li>
										<li><a href="https://iopscience.iop.org/article/10.3847/1538-4357/accc88" class="button primary">Link to publisher version of the paper</a></li>
									</ul>
								</footer>
							</section>

					</div>

				

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
